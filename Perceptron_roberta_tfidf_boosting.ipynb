{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5305c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************\n",
      "* Boosted Perceptron (RoBERTa + TFIDF) *\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"****************************************\")\n",
    "print(\"* Boosted Perceptron (RoBERTa + TFIDF) *\")\n",
    "print(\"****************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f237049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baeca2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(f'data/roberta/roberta.train.csv')\n",
    "new_train=pd.read_csv(f'data/tfidf/tfidf.train.csv')\n",
    "train.iloc[:,-1:]=train.iloc[:,-1:].replace(0,-1)\n",
    "new_train.iloc[:,-1:]=new_train.iloc[:,-1:].replace(0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02463cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(f'data/roberta/roberta.test.csv')\n",
    "new_test=pd.read_csv(f'data/tfidf/tfidf.test.csv')\n",
    "test.iloc[:,-1:]=test.iloc[:,-1:].replace(0,-1)\n",
    "new_test.iloc[:,-1:]=new_test.iloc[:,-1:].replace(0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7199976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.iloc[:,:-1]\n",
    "y_train=train.iloc[:,-1]\n",
    "x_test=test.iloc[:,:-1]\n",
    "y_test=test.iloc[:,-1]\n",
    "new_x_train=new_train.iloc[:,:-1]\n",
    "new_y_train=new_train.iloc[:,-1]\n",
    "new_x_test=new_test.iloc[:,:-1]\n",
    "new_y_test=new_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d36a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x_train.shape[1]):\n",
    "    col = x_train.columns[i]\n",
    "    x_train.rename(columns = {col:'roberta_'+col}, inplace = True)\n",
    "    \n",
    "for i in range(new_x_train.shape[1]):\n",
    "    col = new_x_train.columns[i]\n",
    "    new_x_train.rename(columns = {col:'tfidf_'+col}, inplace = True)\n",
    "    \n",
    "col = new_x_train[new_x_train.columns]\n",
    "x_train = x_train.join(col)\n",
    "\n",
    "for i in range(x_test.shape[1]):\n",
    "    col = x_test.columns[i]\n",
    "    x_test.rename(columns = {col:'roberta_'+col}, inplace = True)\n",
    "    \n",
    "for i in range(new_x_test.shape[1]):\n",
    "    col = new_x_test.columns[i]\n",
    "    new_x_test.rename(columns = {col:'tfidf_'+col}, inplace = True)\n",
    "    \n",
    "col = new_x_test[new_x_test.columns]\n",
    "x_test = x_test.join(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46111a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_b(size):\n",
    "    np.random.seed(42)\n",
    "    w=np.random.normal(-0.01,0.01,size)\n",
    "    w=np.array(w)\n",
    "    b=np.random.normal(-0.01,0.01)\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da4f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,weights,bias):\n",
    "    y_pred = []\n",
    "    for i in x.values: \n",
    "        if (np.dot(weights.transpose(), i)+bias) < 0:\n",
    "            pred = -1 \n",
    "        else:\n",
    "            pred = 1\n",
    "        y_pred.append(pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77dbdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y):\n",
    "    count=0\n",
    "    for i in range(len(y)):\n",
    "        if(y_pred[i]==y[i]):\n",
    "            count+=1\n",
    "    return count/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae652cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,x_train,y_train,lr,w,b):\n",
    "    ilist=[]\n",
    "    devlist=[]\n",
    "    weight_dict={}\n",
    "    accuracy_dict={}\n",
    "    bias_dict={}\n",
    "    index = np.arange(x_train.shape[0])\n",
    "    for i in range(epochs):\n",
    "        np.random.seed(i)\n",
    "        np.random.shuffle(index)\n",
    "        for j in index:\n",
    "            x=x_train.iloc[j]\n",
    "            y=y_train[j]\n",
    "            if(y*(np.dot(w.transpose(),x)+b))<0:\n",
    "                w=w+lr*y*x\n",
    "                b=b+lr*y\n",
    "            weights=w\n",
    "            bias=b\n",
    "    return weights,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01467e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(y_pred,y,d_list):\n",
    "    error=0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]!=y[i]):\n",
    "            error+=d_list[i]\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c39bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_d_list(d_list,alpha,y_pred,y_train):\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i]==y_train[i]):\n",
    "            d_list[i]=d_list[i]*math.exp(-1*alpha)\n",
    "        else:\n",
    "            d_list[i]=d_list[i]*math.exp(alpha)\n",
    "    z=np.sum(d_list)\n",
    "    for i in d_list:\n",
    "        i=i/z\n",
    "    return d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e76b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost(epochs,x_train,y_train,lr,w,b):\n",
    "    size=x_train.shape[0]\n",
    "    d_list=np.ones(size)/size\n",
    "    alpha_list=[]\n",
    "    weight_list=[]\n",
    "    bias_list=[]\n",
    "    for i in range(epochs):\n",
    "        f_w,f_b=fit(20,x_train,y_train,lr,w,b)\n",
    "        y_pred=predict(x_train,f_w,f_b)\n",
    "        error=calculate_error(y_pred,y_train.values.tolist(),d_list)\n",
    "        alpha=0.5*np.log((1-error)/error)\n",
    "        alpha_list.append(alpha)\n",
    "        d_list=update_d_list(d_list,alpha,y_pred,y_train)\n",
    "        weight_list.append(f_w)\n",
    "        bias_list.append(f_b)\n",
    "    return alpha_list,weight_list,bias_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf94662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_boosting(alpha_list,weight_list,bias_list,x):\n",
    "    y_pred=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        pred=0\n",
    "        for j in range(len(alpha_list)):\n",
    "            pred+=alpha_list[j]*(np.dot(weight_list[j].transpose(),x.iloc[i])+bias_list[j])\n",
    "        if pred<0:\n",
    "            y_pred.append(-1)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dcc514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=int(x_train.shape[0] * 0.8)\n",
    "new_x_train=x_train.head(length)\n",
    "new_y_train=y_train.head(length)\n",
    "x_val=x_train.tail(x_train.shape[0]-length)\n",
    "y_val=y_train.tail(x_train.shape[0]-length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6172705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.1\n",
      "1\n",
      "{0.01: 0.8363892806770099, 0.1: 0.8293370944992948, 1: 0.8356840620592384}\n"
     ]
    }
   ],
   "source": [
    "learning_rates=[0.01,0.1,1]\n",
    "epochs=20\n",
    "val_accuracy={}\n",
    "for lr in learning_rates:\n",
    "    print(lr)\n",
    "    w,b=get_w_b(new_x_train.shape[1])\n",
    "    alpha_list,weight_list,bias_list=boost(epochs,new_x_train,new_y_train,lr,w,b)\n",
    "    y_pred_val=predict_boosting(alpha_list,weight_list,bias_list,x_val)\n",
    "    validation_accuracy=accuracy(y_pred_val,y_val.values.tolist())\n",
    "    val_accuracy[lr]=validation_accuracy\n",
    "print(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32bbb8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.01\n",
      "Train set accuracy using averaged perceptron: 0.873448\n",
      "Test set accuracy using averaged perceptron: 0.818302\n"
     ]
    }
   ],
   "source": [
    "best_lr = max(val_accuracy, key=lambda x: val_accuracy[x])\n",
    "print(\"Best learning rate:\", best_lr)\n",
    "w,b=get_w_b(x_train.shape[1])\n",
    "epochs=20\n",
    "alpha_list,weight_list,bias_list=boost(epochs,x_train,y_train,best_lr,w,b)\n",
    "y_pred=predict_boosting(alpha_list,weight_list,bias_list,x_train)\n",
    "print(\"Train set accuracy using averaged perceptron:\",round(accuracy(y_pred,y_train.values.tolist()),6))\n",
    "y_pred=predict_boosting(alpha_list,weight_list,bias_list,x_test)\n",
    "print(\"Test set accuracy using averaged perceptron:\",round(accuracy(y_pred,y_test.values.tolist()),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59bf9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set1=pd.read_csv(f'data/roberta/roberta.eval.anon.csv')\n",
    "eval_set2=pd.read_csv(f'data/tfidf/tfidf.eval.anon.csv')\n",
    "\n",
    "eval_x_train1=eval_set1.iloc[:,:-1]\n",
    "eval_x_train2=eval_set2.iloc[:,:-1]\n",
    "\n",
    "for i in range(eval_x_train1.shape[1]):\n",
    "    col = eval_x_train1.columns[i]\n",
    "    eval_x_train1.rename(columns = {col:'roberta_'+col}, inplace = True)\n",
    "    \n",
    "for i in range(eval_x_train2.shape[1]):\n",
    "    col = eval_x_train2.columns[i]\n",
    "    eval_x_train2.rename(columns = {col:'tfidf_'+col}, inplace = True)\n",
    "    \n",
    "col = eval_x_train2[eval_x_train2.columns]\n",
    "eval_x_train1 = eval_x_train1.join(col)\n",
    "\n",
    "y_pred=predict_boosting(alpha_list,weight_list,bias_list,eval_x_train1)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]==-1:\n",
    "        y_pred[i]=0\n",
    "result=pd.DataFrame(y_pred,columns=['label'],dtype=int)\n",
    "result.index.name='example_id'\n",
    "result.to_csv('boosting_perceptron_roberta_tfidf_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e30ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
